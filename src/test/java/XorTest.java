import org.junit.Test;

import com.neural.NeuralNetwork;

import static org.junit.Assert.*;

/*
 * This Java source file was auto generated by running 'gradle init --type java-library'
 * by 'colin_000' at '09/03/18 8:44 PM' with Gradle 2.14.1
 *
 * @author colin_000, @date 09/03/18 8:44 PM
 */
public class XorTest {
    @Test public void sanityTest() {
    	int numLayers[] = {2, 3, 2};
        NeuralNetwork network = new NeuralNetwork(numLayers, 1, 0.1, NeuralNetwork.ACTIVATION_FUNC.RELU);
        
        double inputs[] = {1, 1};
        
        double outputs[] = network.goThroughNetwork(inputs, false, null);
        
        assertEquals(outputs.length, 2);
        //assertTrue(outputs[0] >= 0 && outputs[0] <= 1);
        //assertTrue(outputs[1] >= 0 && outputs[1] <= 1);
        
        System.out.println(outputs[0] + ", " + outputs[1]);
    }
    
    @Test public void trainingSimpleXORReLU() {
    	System.out.println("trainingSimpleXORReLU beginning");
    	
    	int numLayers[] = {2, 2, 1};
        NeuralNetwork network = new NeuralNetwork(numLayers, 0.1, 0.5, NeuralNetwork.ACTIVATION_FUNC.RELU);
        
        double inputs[][] = {{1, 1}, {0, 1}, {1, 0}, {0, 0}};
        double idealOutputs[][] = {{0}, {1}, {1}, {0}};
        
        for(int i = 0; i < 10000; ++i){
        	for(int k = 0; k < inputs.length; ++k){
        		double outputs[] = network.goThroughNetwork(inputs[k], true, idealOutputs[k]);
    	        
    	        assertEquals(outputs.length, 1);
    	        //assertTrue(outputs[0] >= 0 && outputs[0] <= 1);
    	        
    	        // System.out.println("Round " + (k + 1) + " of set " + (i + 1) + ": " + outputs[0]);
        	}
        }
        
        for(int k = 0; k < inputs.length; ++k){
    		double outputs[] = network.goThroughNetwork(inputs[k], false, null);
	        
	        assertEquals(outputs.length, 1);
	        //assertTrue(outputs[0] >= 0 && outputs[0] <= 1);
	        
	        System.out.println("Round " + (k + 1) + ": " + outputs[0]);
	        
	        assertTrue(Math.abs(outputs[0] - idealOutputs[k][0]) < 0.1);
    	}
    }
    
    @Test public void trainingSimpleXORSigmoid() {
    	System.out.println("trainingSimpleXORSigmoid beginning");
    	
    	int numLayers[] = {2, 2, 1};
        NeuralNetwork network = new NeuralNetwork(numLayers, 0.1, 0.5, NeuralNetwork.ACTIVATION_FUNC.SIGMOID);
        
        double inputs[][] = {{1, 1}, {0, 1}, {1, 0}, {0, 0}};
        double idealOutputs[][] = {{0}, {1}, {1}, {0}};
        
        for(int i = 0; i < 10000; ++i){
        	for(int k = 0; k < inputs.length; ++k){
        		double outputs[] = network.goThroughNetwork(inputs[k], true, idealOutputs[k]);
    	        
    	        assertEquals(outputs.length, 1);
    	        assertTrue(outputs[0] >= 0 && outputs[0] <= 1);
    	        
    	        // System.out.println("Round " + (k + 1) + " of set " + (i + 1) + ": " + outputs[0]);
        	}
        }
        
        for(int k = 0; k < inputs.length; ++k){
    		double outputs[] = network.goThroughNetwork(inputs[k], false, null);
	        
	        assertEquals(outputs.length, 1);
	        assertTrue(outputs[0] >= 0 && outputs[0] <= 1);
	        
	        System.out.println("Round " + (k + 1) + ": " + outputs[0]);
	        
	        assertTrue(Math.abs(outputs[0] - idealOutputs[k][0]) < 0.1);
    	}
    }
    
    @Test public void trainingSimpleNANDReLU() {
    	System.out.println("trainingSimpleNANDReLU beginning");
    	
    	int numLayers[] = {2, 2, 1};
        NeuralNetwork network = new NeuralNetwork(numLayers, 0.1, 0.1, NeuralNetwork.ACTIVATION_FUNC.RELU);
        
        double inputs[][] = {{1, 1}, {0, 1}, {1, 0}, {0, 0}};
        double idealOutputs[][] = {{0}, {1}, {1}, {1}};
        
        for(int i = 0; i < 10000; ++i){
        	for(int k = 0; k < inputs.length; ++k){
        		double outputs[] = network.goThroughNetwork(inputs[k], true, idealOutputs[k]);
    	        
    	        assertEquals(outputs.length, 1);
    	        //assertTrue(outputs[0] >= 0 && outputs[0] <= 1);
    	        
    	        // System.out.println("Round " + (k + 1) + " of set " + (i + 1) + ": " + outputs[0]);
        	}
        }
        
        for(int k = 0; k < inputs.length; ++k){
    		double outputs[] = network.goThroughNetwork(inputs[k], false, null);
	        
	        assertEquals(outputs.length, 1);
	        //assertTrue(outputs[0] >= 0 && outputs[0] <= 1);
	        
	        System.out.println("Round " + (k + 1) + ": " + outputs[0]);
	        
	        assertTrue(Math.abs(outputs[0] - idealOutputs[k][0]) < 0.1);
	        
	        
    	}
    }
    
    @Test public void trainingSanityLotsOfInputs() {
    	System.out.println("trainingSanityLotsOfInputs beginning");
    	
    	int numLayers[] = {4096, 2048, 3};
        NeuralNetwork network = new NeuralNetwork(numLayers, 1, 1, NeuralNetwork.ACTIVATION_FUNC.RELU);
        
        double inputs[][] = new double[1][];
        inputs[0] = new double[4096];
        
        for(int i = 0; i < 4096; ++i){
        	inputs[0][i] = 1;
        }
        
        double idealOutputs[][] = {{0, 0, 0}};
        
        for(int i = 0; i < 2; ++i){
        	for(int k = 0; k < inputs.length; ++k){
        		double outputs[] = network.goThroughNetwork(inputs[k], true, idealOutputs[k]);
    	        
        		assertEquals(outputs.length, 3);
    	        for(int j = 0; j < outputs.length; ++j){
    	        	//assertTrue(outputs[j] >= 0 && outputs[j] <= 1);
    	        }
    	        
    	        // System.out.println("Round " + (k + 1) + " of set " + (i + 1) + ": " + outputs[0]);
        	}
        }
        
        for(int k = 0; k < inputs.length; ++k){
    		double outputs[] = network.goThroughNetwork(inputs[k], false, null);
	        
	        assertEquals(outputs.length, 3);
	        for(int j = 0; j < outputs.length; ++j){
	        	//assertTrue(outputs[j] >= 0 && outputs[j] <= 1);
	        }
	        
	        //assertTrue(Math.abs(outputs[0] - idealOutputs[k][0]) < 0.1);
	        
	        System.out.println("Round " + (k + 1) + ": " + outputs[0]);
    	}
    }
}

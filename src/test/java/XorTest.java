import org.junit.Test;

import com.neural.NeuralNetwork;

import junit.framework.AssertionFailedError;

import static org.junit.Assert.*;

/*
 * This Java source file was auto generated by running 'gradle init --type java-library'
 * by 'colin_000' at '09/03/18 8:44 PM' with Gradle 2.14.1
 *
 * @author colin_000, @date 09/03/18 8:44 PM
 */
public class XorTest {
	
	public void doTest(int numLayers[], 
								double inputs[][],
								double idealOutputs[][],
								NeuralNetwork.ACTIVATION_FUNC[] activationFuncs, 
								NeuralNetwork.WEIGHT_INIT_FUNC weightFunc,
								int numIterations){        
        for(int numAttempts = 0; numAttempts < 5; ++numAttempts){
        	NeuralNetwork network = new NeuralNetwork(numLayers, 0.1, 0.5, activationFuncs, weightFunc);
	        doTestInner(network, inputs, idealOutputs, numIterations);
	        
	        if(CheckNetworkPassed(network, inputs, idealOutputs)){
	        	return;
	        } else {
	        	System.out.println("Network did not converge on correct solution. Assuming it fell into a local minimum instead of global minimum");
	        }
		}
		
		fail("Neural network did not converge on the correct solution after 5 attempts. Test failed");
	}
	
	public void doTest(int numLayers[], 
								double inputs[][],
								double idealOutputs[][],
								NeuralNetwork.ACTIVATION_FUNC activationFunc, 
								NeuralNetwork.WEIGHT_INIT_FUNC weightFunc, 
								int numIterations){
		
		for(int numAttempts = 0; numAttempts < 5; ++numAttempts){
	        NeuralNetwork network = new NeuralNetwork(numLayers, 0.1, 0.5, activationFunc, weightFunc);
	        doTestInner(network, inputs, idealOutputs, numIterations);
	        
	        if(CheckNetworkPassed(network, inputs, idealOutputs)){
	        	return;
	        } else {
	        	System.out.println("Network did not converge on correct solution. Assuming it fell into a local minimum instead of global minimum");
	        }
		}
		
		fail("Neural network did not converge on the correct solution after 5 attempts. Test failed");
	}
	
	public NeuralNetwork doTestInner(NeuralNetwork network, double inputs[][], double idealOutputs[][], int numIterations){
		for(int i = 0; i < numIterations; ++i){
        	for(int k = 0; k < inputs.length; ++k){
        		double outputs[] = network.goThroughNetwork(inputs[k], true, idealOutputs[k]);
    	        
    	        assertEquals(outputs.length, idealOutputs[k].length);
    	        //assertTrue(outputs[0] >= 0 && outputs[0] <= 1);
    	        
    	        // System.out.println("Round " + (k + 1) + " of set " + (i + 1) + ": " + outputs[0]);
        	}
        }
		
		return network;
	}
	
	public boolean CheckNetworkPassed(NeuralNetwork network, double inputs[][], double idealOutputs[][]){
		for(int k = 0; k < inputs.length; ++k){
    		double outputs[] = network.goThroughNetwork(inputs[k], false, null);
	        
	        assertEquals(outputs.length, idealOutputs[k].length);
	        //assertTrue(outputs[0] >= 0 && outputs[0] <= 1);
	        
	        System.out.println("Round " + (k + 1) + ": " + outputs[0]);
	        
	        if(Math.abs(outputs[0] - idealOutputs[k][0]) >= 0.1){
	        	return false;
	        }
    	}
		
		return true;
	}
	
    @Test public void sanityTest() {
    	System.out.println("sanityTest beginning");
    	int numLayers[] = {2, 3, 2};
        NeuralNetwork network = new NeuralNetwork(numLayers, 1, 0.1, NeuralNetwork.ACTIVATION_FUNC.RELU, null);
        
        double inputs[] = {1, 1};
        
        double outputs[] = network.goThroughNetwork(inputs, false, null);
        
        assertEquals(outputs.length, 2);
        //assertTrue(outputs[0] >= 0 && outputs[0] <= 1);
        //assertTrue(outputs[1] >= 0 && outputs[1] <= 1);
        
        System.out.println(outputs[0] + ", " + outputs[1]);
    }
    
    @Test public void sanityTestOnlyInputs() {
    	System.out.println("sanityTestOnlyInputs beginning");
    	int numLayers[] = {2};
        NeuralNetwork network = new NeuralNetwork(numLayers, 1, 0.1, NeuralNetwork.ACTIVATION_FUNC.NONE, null);
        
        double inputs[] = {1, 1};
        
        double outputs[] = network.goThroughNetwork(inputs, false, null);
        
        assertEquals(outputs.length, 2);
        
        System.out.println(outputs[0] + ", " + outputs[1]);
        
        assertTrue(outputs[0] == 1 && outputs[1] == 1);
    }
    
    @Test public void trainingSanityLotsOfInputs() {
    	System.out.println("trainingSanityLotsOfInputs beginning");
    	
    	int numLayers[] = {200, 100, 3};
        NeuralNetwork network = new NeuralNetwork(numLayers, 1, 1, NeuralNetwork.ACTIVATION_FUNC.RELU, null);
        
        double inputs[][] = new double[1][];
        inputs[0] = new double[200];
        
        for(int i = 0; i < 200; ++i){
        	inputs[0][i] = 1;
        }
        
        double idealOutputs[][] = {{0, 0, 0}};
        
        for(int i = 0; i < 2; ++i){
        	for(int k = 0; k < inputs.length; ++k){
        		double outputs[] = network.goThroughNetwork(inputs[k], true, idealOutputs[k]);
    	        
        		assertEquals(outputs.length, 3);
    	        for(int j = 0; j < outputs.length; ++j){
    	        	//assertTrue(outputs[j] >= 0 && outputs[j] <= 1);
    	        }
    	        
    	        // System.out.println("Round " + (k + 1) + " of set " + (i + 1) + ": " + outputs[0]);
        	}
        }
        
        for(int k = 0; k < inputs.length; ++k){
    		double outputs[] = network.goThroughNetwork(inputs[k], false, null);
	        
	        assertEquals(outputs.length, 3);
	        for(int j = 0; j < outputs.length; ++j){
	        	//assertTrue(outputs[j] >= 0 && outputs[j] <= 1);
	        }
	        
	        //assertTrue(Math.abs(outputs[0] - idealOutputs[k][0]) < 0.1);
	        
	        System.out.println("Round " + (k + 1) + ": " + outputs[0]);
    	}
    }
    
    @Test public void trainingSimpleXORReLU() {
    	System.out.println("trainingSimpleXORReLU beginning");
    	int numLayers[] = {2, 3, 1};
        double inputs[][] = {{1, 1}, {0, 1}, {1, 0}, {0, 0}};
        double idealOutputs[][] = {{0}, {1}, {1}, {0}};
        
        doTest(numLayers, inputs, idealOutputs, NeuralNetwork.ACTIVATION_FUNC.RELU, null, 150000);
    }
    
    @Test public void trainingSimpleXORSigmoid() {
    	System.out.println("trainingSimpleXORSigmoid beginning");
    	int numLayers[] = {2, 2, 1};
        double inputs[][] = {{1, 1}, {0, 1}, {1, 0}, {0, 0}};
        double idealOutputs[][] = {{0}, {1}, {1}, {0}};

        doTest(numLayers, inputs, idealOutputs, NeuralNetwork.ACTIVATION_FUNC.SIGMOID, null, 10000);
    }
    
    @Test public void trainingSimpleNANDReLU() {
    	System.out.println("trainingSimpleNANDReLU beginning");
    	
    	int numLayers[] = {2, 3, 1};
        double inputs[][] = {{1, 1}, {0, 1}, {1, 0}, {0, 0}};
        double idealOutputs[][] = {{0}, {1}, {1}, {1}};
        
        doTest(numLayers, inputs, idealOutputs, NeuralNetwork.ACTIVATION_FUNC.RELU, null, 90000);
    }
    
    @Test public void trainingSimpleNANDTanh() {
    	System.out.println("trainingSimpleNANDTanh beginning");
    	
    	int numLayers[] = {2, 2, 1};
        double inputs[][] = {{1, 1}, {0, 1}, {1, 0}, {0, 0}};
        double idealOutputs[][] = {{0}, {1}, {1}, {1}};
        
        doTest(numLayers, inputs, idealOutputs, NeuralNetwork.ACTIVATION_FUNC.TANH, null, 40000);
    }
    
    @Test public void trainingSimpleNANDReLUSigmoidMix() {
    	System.out.println("trainingSimpleNANDReLUSigmoidMix beginning");
    	
    	int numLayers[] = {2, 2, 1};
    	NeuralNetwork.ACTIVATION_FUNC activationFuncs[] = {
    			NeuralNetwork.ACTIVATION_FUNC.NONE,
    			NeuralNetwork.ACTIVATION_FUNC.RELU,
    			NeuralNetwork.ACTIVATION_FUNC.SIGMOID
    			};
        
        double inputs[][] = {{1, 1}, {0, 1}, {1, 0}, {0, 0}};
        double idealOutputs[][] = {{0}, {1}, {1}, {1}};
        
        doTest(numLayers, inputs, idealOutputs, activationFuncs, null, 20000);
    }
    
    @Test public void trainingSimpleXORTanhXavier() {
    	System.out.println("trainingSimpleXORTanhXavier beginning");
    	
    	int numLayers[] = {2, 2, 1};
        double inputs[][] = {{1, 1}, {0, 1}, {1, 0}, {0, 0}};
        double idealOutputs[][] = {{0}, {1}, {1}, {0}};
        
        doTest(numLayers, inputs, idealOutputs, NeuralNetwork.ACTIVATION_FUNC.TANH, NeuralNetwork.WEIGHT_INIT_FUNC.XAVIER_MODIFIED, 50000);
    }
    
    @Test public void trainingSimpleNANDTanhXavier() {
    	System.out.println("trainingSimpleNANDTanhXavier beginning");
    	
    	int numLayers[] = {2, 2, 1};
        double inputs[][] = {{1, 1}, {0, 1}, {1, 0}, {0, 0}};
        double idealOutputs[][] = {{0}, {1}, {1}, {1}};
        
        doTest(numLayers, inputs, idealOutputs, NeuralNetwork.ACTIVATION_FUNC.TANH, NeuralNetwork.WEIGHT_INIT_FUNC.XAVIER_MODIFIED, 5000);
    }
    
    @Test public void trainingSimpleNANDReLUXavier() {
    	System.out.println("trainingSimpleNANDReLUXavier beginning");
    	
    	int numLayers[] = {2, 3, 1};
        double inputs[][] = {{1, 1}, {0, 1}, {1, 0}, {0, 0}};
        double idealOutputs[][] = {{0}, {1}, {1}, {1}};
        
        doTest(numLayers, inputs, idealOutputs, NeuralNetwork.ACTIVATION_FUNC.RELU, NeuralNetwork.WEIGHT_INIT_FUNC.XAVIER_MODIFIED, 20000);
    }
    
    @Test public void trainingSimpleXORReLUXavier() {
    	System.out.println("trainingSimpleXORReLUXavier beginning");
    	
    	int numLayers[] = {2, 3, 1};
        double inputs[][] = {{1, 1}, {0, 1}, {1, 0}, {0, 0}};
        double idealOutputs[][] = {{0}, {1}, {1}, {0}};
        
        doTest(numLayers, inputs, idealOutputs, NeuralNetwork.ACTIVATION_FUNC.RELU, NeuralNetwork.WEIGHT_INIT_FUNC.XAVIER_MODIFIED, 50000);
    }
}
